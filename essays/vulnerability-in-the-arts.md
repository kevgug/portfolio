---
title: "Creativity doesn't define the arts"
date: "2025-10-25"
publish: false
---

## Concert

Last Wednesday, I spent the night before my neuroscience exam productively—at a Balu Brigada concert. Towards the end of the show, one of the performing brothers said something unassumingly profound and made me rethink how we define art.

He announced they were about to perform _Butterfly Boy_, admittedly not the most popular song on their new album, but one that best reflects how they are, at their core, just a bunch of vulnerable guys. While this specific song is explicitly about vulnerability, I believe that all art is built on the foundation of vulnerability.

> Without vulnerability, even the most expressive content is not art.

![Balu Brigada performing "Butterfly Boy" on a purple-lit stage at Thalia Hall in Chicago, with ornate balconies, decorative moldings, and a large crowd in the foreground](balu-brigada-butterfly-boy.jpeg)
_Balu Brigada performing their song *Butterfly Boy* in Thalia Hall, Chicago_

Most definitions of art revolve around _creation_: the act or output of creating something that intends to evoke some perception. To better define creation, I like the idea that "all design is redesign"—everything is based literally or inspirationally on what has come before, even if the new creative work appears completely distinct. But defining art as intentional creation misses half of the picture.

If we agree that art is about evoking some expected perception, then the difference of the actual perception should also matter. “Art for art’s sake” is when you associate some creative work with yourself and have zero expectations for the perception. Most artists carry expectations and a blacklist for what perceptions they’d like to see. Small deviations from expectations create joy and validation for the artist, whereas large deviations create intrigue and perspective. Some large deviations fall on the artist’s—mostly tacit—blacklist to create shock and disappointment.

If I'm right about vulnerability, then we're missing half of the picture: the recipient's perception.

In that case, then creativity alone isn't enough to call something valid _art_. It would also mean that the concert was time well spent leading up to my exam. But what exactly is vulnerability and why does it make something art? [1]

## The art of gifting

Let's begin with a simply analogy for art: gift giving. In a way, gifting _is_ art in and of itself.

Why do inexpensive but thoughtful gifts mean much more to the recipient than expensive gifts? Why does a handwritten birthday letter mean much more to us than a 'happy birthday' text message? The obvious reason is the extra time investment—for choosing that personal gift or handwriting that card—signals care for the recipient. It is worth noting that signaling care for someone is socially costly: imagine the social embarassment from signalling care for someone who doesn't think much of you. Therefore you are being vulnerable. The fact that we generally prefer the inexpesnive but thoughtful gift over the expensive gift shows that we value the giver's financial cost less than their social cost: we value when others are being vulnerable when providing us value. The tangible value is boosted by the intangible determined by the level of vulnerability of the giver.

Gift giving is highly analogous to art. While we might not ever personally know the creator, we know they are being vulnerable for people like us, and we appreciate that deeply. Between an inherentally valuable item with little thinking involved and an inherentally less valuable item with more thinking involved, we tend to choose the latter. Is there some way to model this phonomenon, even if just at a very high level?

## Uniquely human

Why is vulnerability exclusive to humans? In short, because there's only one of us living a finite life.

Creativity is necessary but insufficient. Vulnerability is necessary but insufficient, too. Only creation can be automated. Vulnerability depends on singularness and impermanence/time-constraint of life: reputational risk and opportunity cost. If we lived forever, we'd have infinite time to redefine ourselves an infinite amount of times. When there's a limited amount of time, it's much harder to change your narrative.

[Introduce idea of narrative stakes.]

For every recipient:

$$
V \propto e^{-\lambda t}
$$

$$
\lim\_{t \to \infty} V = 0
$$

But what about when someone fakes vulnerability, whether explicitly through the content or through the implied effort of the creative work? Wouldn’t that undermine the idea of stakes and mean even fully AI generated content can be passed off as art?

## Performative vulnerability

Consider these three verses. Only one is a real verse in _Butterfly Boy_, while the others are AI generated lyrics. Would you consider one more **vulnerable** than the other?

<br>

**Sample A**:

> I broke down at the grocery store, the weight\
> Of all these expectations pressing down\
> Too hard—I'm learning it's okay to not be great\
> At holding up the world when I might drown\

**Sample B**:

> And it's better to feel something than nothing\
> But the fragility is killing me with\
> Skin thinner than a butterfly\
> Mood swinging with the changing tides again\

**Sample C**:

> They see someone who's supposed to have it all\
> But I'm just colors bleeding in the rain\
> I'm terrified of mirrors in the hall\
> That show me someone I can't quite explain

<br>

Assuming you don't already know the song
Would you surprised if I told you the correct verse was sample A? Or sample C? Assuming you haven't heard the song before, I presume you would've simply accepted either as fact, even though they're both AI generated. Ignoring All are comparably expressive

It's about making associations. It's all about perception.

- You can be deceived, only if you're (1) told a lie and (2) believe it. Deceit means you've made a false association between some creator and the creative piece.
- If you're (1) told a lie and (2) don't believe it, then you don't make the association between the supposed creator and the creative piece.
- If you're (1) told the truth and (2) don't believe it, then you also don't make the association between the actual creator and the creative piece.
- If you're (1) told the truth and (2) believe it, then you've formed a correct association between the actual creator and the creative piece, which we can now call the artist and the art.

Here is a 2x2 matrix summarizing these scenarios:

|                   | **Creator was vulnerable**   | **Creator was not vulnerable** |
| ----------------- | ---------------------------- | ------------------------------ |
| **Believe**       | Correct association<br>→ Art | False association<br>→ Art     |
| **Don't believe** | False rejection<br>→ Not art | Correct rejection<br>→ Not art |

Association between the creative work and some creator. Importantly, it's not about believing whether the output is creative or not—that's already been established. It's about whether the creator of the creative output was vulnerable in making it.

Performatively vulnerable ≠ truly vulnerable.

So yes, as I’m sure you’ve also observed, AI output can be seen as art. But the 2x2 matrix shows why when people are made aware of something being entirely AI generated, they suddenly stop labelling the output art. [2]

But there's a cost to being performatively vulnerable: there are repurcussions to over-crediting creative work as yours.

$$
R = \alpha \sum_{r=1}^N \left[ \max\{0, C_{\text{perceived},r} - C_{\text{actual}}\} \times I_r \right]
$$

Where:

- $$r$$ is a **recipient** of the creative work
- $$N \geq 0 $$ is the **number of recipients** (typically includes the creator too)
- $$C_{\text{perceived},r} \in [0,1]$$ is $$r$$'s **perception** of the creator's contribution to the creative work.
- $$C_{\text{actual}} \in [0,1]$$ is the creator's **actual** contribution to the creative work.
- $$I_r \in \mathbb{R}$$ is the creative work's impact on recipient $$r$$
- $$\alpha \geq 1$$ is the **over-credit penalty multiplier**;

If we take this 2x2 matrix, we can use it to try to formalize a model for vulnerability.

## Modelling vulnerability

The 2x2 matrix explains the thought process recipients have in deciding whether creative work is art or not. We can call some recipient $$r$$'s perceived contribution as $$C_{\text{perceived},r}$$, while the creator's actual contribution is $$C_{\text{actual}}$$.

How some recipient $$r$$ perceives the creator's vulnerability:

$$
V_{\text{perceived},r} = C_{\text{perceived},r} \times |I_r| \times \delta(t_r)
$$

Vulnerability of the creator:

$$
V = C_{\text{actual}} \times \sum\_{r=1}^{N} V_{\text{perceived},r}
$$

Where time discount factor $$\delta(t) = e^{-\lambda t}$$ and $$\lambda$$ is the decay rate for memory (i.e., forgetfulness). For the sake of simplicity, let's assume everyone has the same $$\lambda$$ for every creative work they encounter. As time goes on, the time discount factor will become closer to zero, until stakes to the creator ultimately becomes negligible.

$$
\lim\_{t \to \infty} V = 0
$$

(As we proposed earlier.)

This reflect how people will forget about each creative work with time. For AI, the lifespan can be infinite, and so the time discount will reach zero for every creative output. That means the stakes for each AI generated creative output is eventually always zero. I'd argue that's a strong enough basis to reject that AI could ever be vulnerable, since it is ultimately never putting anything on the line.

The key assumption I'm making is that a valid contribution requires having some expectation of what impact you want—also known as intent. When you create with intent, you are invested in the impact matching your intent as closely as possible. So the first point is, the creator is exposing themselves to the risk of disappointment if their creative work falls short of their desired impact. For example, imagine painting a rabbit only for people to mistake it as a duck—that would be disappointing.

At the same time, it's in the creator's best interest to actively think through how to achieve the desired impact. As long as the creator thinks that their recipients believe that creatoes necessarily expose themselves to potential disappointment, the creator is exposing themselves to potential embarassment too. So the second point is, while the recipients don't necessarily know what the creator intends through their work, knowing that the creator intends _something_ can incur a social cost. This cost is embarrassment for the creator when they know some recipient knows they didn't achieve their goal; the recipient doesn't need to know exactly what the creator intended, it is enough to pick up on the creator's disappointment. [3]

Between disappointment and embarassment, the potential for even one makes intentional creation a vulnerable act. But there's one last case I'm interested in understanding. What about the increasingly common case where humans use AI to create something—at what point is the creative work no longer vulnerable and so no longer art?

## Modelling taste

I strongly disagree with the idea that user interface design is not an art because it is purely about solving user problems.

I believe good “Taste” is functional art, but art nonetheless. It is the ability to produce some desired perceptions of utility. Utility in the product sense: consistent, on-brand design with the right balance of form and function. Figma CEO, Dylan Field, talking about taste being nonnegotiable in the AI age, this is what I understand taste is.

Modelling as utility to recipients.

$$
Q = \frac{\sum_{r=1}^N{U_r}}{N}
$$

- $$U_r \in \mathbb{R}$$

Utility is composed of both anticipated factors and unanticipated factors:

$$
U_r = U_{\text{anticipated},r} + U_{\text{unanticipated},r}
$$

- $$U_{\text{anticipated},r} \in \mathbb{R}$$
- $$U_{\text{unanticipated},r} \in \mathbb{R}$$

We can say there are $$k$$ anticipated factors of utility, weighted by $$\beta$$'s which sum to 1:

$$
U_{\text{anticipated},r} = \beta_0 U_{0,r} + \beta_1 U_{1,r} + ... + \beta_k U_{k,r}
$$

- $$\beta_i \in [-1,1]$$ is how well the design performs for factor $$i$$
- $$U_{i,r}$$ is the utility to recipient $$r$$ of having factor $$i$$ maxed out

(the unanticpated utility is unknown, so we can include it like an error term in a linear regression model)

What about time constancy? Art requires vulnerability, but function doesn't change: something that was functional will stay functional. If no vulernability in functional design (like software product design, where the creator is trying to maximize taste), then functional design is not necessarily art.

It's key to note that keeping a function/feature is just as much a decision as adding a function/feature. In fact it's easier to add than to remove features, since the local maximum accepting mindset (keep status quo) often exceeds the global maximum seeking mindset (take one step back to take two steps forwards). By that understanding, as long as someone is baseline maintaining some creative work, they are putting active thought into which features the creative wok should have.

Naturally an indiviudal product designer can be a small cog in large system, less vulenrability... but add up / company vulnerability (?)

So good design taste is an art. If art is defined only by skillful intentional creativity, then can good taste be imitated by AI. If art is defined by vulnerable creation, then good taste can't be imitated by even the most intelligent AI system. How is this represented in the model?

Because good taste requires vulnerability (it is art), then it falls into the anticipated utility function as a nonzero factor (i.e., $$\beta_0 = x$$ and $$U_{0,r} = V_{\text{perceived}, r}$$):

$$
U_{\text{anticipated},r} = x V_{\text{perceived},r} + \beta_1 U_{1,r} + ... + \beta_k U_{k,r}
$$

If you think vulnerability doesn't matter to UI design, then I'm also happy to shove it into the linear combination of unanticipated factors:

$$
U_{\text{unanticipated},r} = x V_{\text{perceived},r} + \gamma_1 U_{1,r} + ... + \gamma_m U_{m,r}
$$

If you neglect vulnerability, and

## Human-AI interop

Let's test my vulnerability framework on one of the more contentious topics today: AI generated art. I have two pretty good examples in my grandparents—helpfully, one is an artist by trade.

I've made this observation, connecting to the 2x2 matrix: Older generations may be used to associating a creative output with a human creator, so they automatically believe. This either creates a correct association to a human creator (artist), which is what they're used to, or a false association between the creative piece and a non-existent human creator (AI). Once they're made aware of the truth that the work was fully AI generated, though, they no longer believe in the association between work and some supposed human creator (creator was vulnerable)

We can create artificial scarcity in the lives of AI personas that delineate their output. e.g., a Twitter bot. There are no stakes in the reputational risk of an AI persona. Because vulnerability requires the impermanence of the creator. AI personas can live on forever.

Associating yourself with output is enough to satisfy the requirement for vulnerability. My dad generating song with Suno for my grandmother in French with specific details like the current date and names of family members. Does she understanding that no human created that song? Probably not; it is genuinely convincing and quite good. I'd argue that the claim of how much my dad prompted the model to produce that exact output doesn't matter—it only matters whether my grandmother forms the association that my dad produced the song, the means of production being irrelevant. So to my grandmother, the song is art. To me, the song is not art because I make more of an association to Suno than to my dad: I don't perceive much vulnerability, other than my dad claiming he created the song (because he prompted Suno with the specific details).

How about my other grandmother, who paints for a living. Knowing her, I have a direct association between her and her creative output.

![Acrylic winter landscape of Dischma Valley in Davos by Eveline Henner in 1976](eveline-henner-winter-landscape-dischma-valley.jpg)
_*Dischma Valley, Davos* by Eveline Henner (1976)_

It felt really sacriligeous doing this, but for research purposes, I AI generated new art in her style (sorry, grand-mère).

![Fake AI generated outline of an imitation of Eveline Henner's natural cubist style](fake-ai-eveline-henner-chicago-navy-pier-outline.png)
_AI generated outline of an imitation of Eveline Henner's natural cubist style_

![Fake AI generated imitation of Eveline Henner's natural cubist style](fake-ai-eveline-henner-chicago-navy-pier.png)
_AI generated imitation of Eveline Henner's natural cubist style_

As for anyone else who knows my grandmother, my visceral feelings at seeing this are disgust. It feels unacceptable that

But how little work do I have to do before my association with the creative output is false? In other words, how little of the _creating_ can I get away with?

- Imagine that I painted that on canvas in the style of my grandmother, as an homage to her talent. I create everything from the pencil outline to the paint. I presume that would be well received.
- Now imagine I got AI to generate just the pencil outline for the painting. While less creative, I still go through the effort of copying over the pencil marks to the canvas by eye and painting in the gaps. I presume that would still be well received.
- Now imagine I got AI to generate the colors too; I would still have to go through the effort of sketching the pencil outline, mixing the acrylic paint to create the right color, and painting in the right gaps with the right mix of paint. It's still a decent bit of effort that shows I'm paying homage to my grandmother.
- Now imagine I also ask AI to tell me exactly which paints to buy and mix in exact amounts to match the colors on the AI generated reference painting. Now something's starting to feel a bit off—I'm no longer putting any active thinking into the creation of the painting. But following all those steps over likely hundreds of shades of paint still reflects effort and would probably be appreciated by my grandmother.
- The next step is where things break down: imagine I print out the AI generated painting onto canvas using an art studio printer. Other than the financial cost of printing the painting, I haven't put any considerable effort into the output. Additionally, the gesture will likely come across less as a thoughtful gift and more as a "hey, look how easy it is for anyone to replicate your art and print it as if it were a real print!"
- The most extreme version is I AI generate the painting and send her the piece in an email. I don't think anyone would expect any appreciation for that.

At which point is association between me and the output broken? It's when I don't need active thinking. Because active thinking means I'm openly expressing my thoughts, which is vulnerable. If i'm not openly expressing my thoughts to the recipient, then I am not being vulnerable, and there is no social cost related to my thoughts if my grandmother doesn't like the imitation piece. Ironically there will still be social cost, only it's due to signalling my lack of appreciation for the joint creative skills, sure, but also vulnerability she has to go through to create her piece.

## Generalizability

How about something not explicitly vulnerable? All genres of music, from the soft-spoken [_say something_](https://royelotis.lnk.to/saysomething) by Royel Otis to the more provocative [_Differently_](https://bru-c.lnk.to/differentlyID) by Bru-C.

Music
Acting
Writing
Drawing
Painting
...

## Notes

[1] For the record: I asked my friend to quiz me in the backseat of the Uber to and from the venue, which gave me ample preparation. I'd say he's the number one reason my exam didn't go sideways in the end. Even when we got inside the venue, I managed to find a way to convince him to keep quizing me—until the band showed up, that is. And yes, I don't deserve his friendship (thanks Ronan).

[2] I appreciate that I may be imposing my own definition of art by excluding fully AI generated work. I'm not saying my model is empirical fact, it's just my anecdotal best guess.

[3] ... for machines, we call this direction/quality/obedience(?) `!TODO` Dissapointment isn't the only possible effect of not achieving your desired impact—you can also be intrigued

[...] there might be intent in sending someone ai gen output but that isnt related to whether someone has stakes/vulenrability in doing so. like you said, that actual can speak against it. creator intent is something separate, not to be confused with vulnerability
